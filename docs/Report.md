### Report

This project explores how weather can be predicted in a given time by values of weather indicators or by simply an image at a particular time. The implementations or results between those two approaches will be compared with data in a specific period of time (09/01/2017 - 10/31/2017) as the experimental input. Since data prior to 09/01/2017 is used for training the model, the better approach will be found out under the same initial circumstances.

All original data are downloadable under the project’s description. There are two sets of data: one set came from Vancouver Airport weather station that contains the values of weather indicators, and the other is a bunch of images taken by Kat Kam somewhere in downtown. Before utilizing the data immediately, data cleaning and refinement are necessary since 1. Data is read in format of Spark dataframe, partitioned in files, I’d rather convert it into Pandas to make it easier for operations; 2. There are rows in the original .csv input file that are useless or meaningless; 3. Columns may be needed to be split or redefined; 4. Some weather description should be excluded for convenient classification. etc. At the beginning I tried to deal with those data on Spark dataframe because there is more than one .csv input file. But afterward I found it inefficient when doing operations on data with Spark. Also, another advantage of converting the data into Pandas dataframe right after reading in the original data would be, when clearing up the data, the ease of exporting it into a single file without coalescing it with Spark, if the size of data is small.

The two methods of weather prediction are implemented in separate scripts and they both read the cleaned input data as described above. So they are processing independently to each other. As known, Machine learning (with scikit-learn) enables us to predict something by classification using a model after being trained on data with known results, which means the data is split into two parts: one, with both x and y values, used for training; and the other, with only unseen x values, for prediction. It is difficult because this is actually a multi-label classification problem since there is probably more than one sub-class for each category, like ‘heavy rain’, where the former of the phrase describes the degree of the later. This does make significant difference because each label appearing in y, the target data, should be classified and treated independently. In scikit-multilearn package, this can be achieved by transforming y (originally a series in Pandas dataframe) into a sparse matrix, with every label representing a column. And for every observation of weather data, an entry of ‘1’ implies the presence of corresponding label, otherwise ‘0’.

As for the Predict-by-image approach, another difficulty that I have encountered the first time is that how to read all the images in one folder into my program and represent them as a 2-d array containing features as inputs. There are some nice ideas on the internet showing that some package like ‘cv2’ is able to read image files very efficiently, into a format of a n-d array (RGB values). Therefore, all images can be read one by one in a for loop. Moreover, for each image loaded, the time the image was taken can be determined and the image can be easily reshaped into a 1-d array as wanted. One thing to notice is that the number of images is less than the number of weather observations, this is why we need to know the time of the image so that those weather data matched by the images are considered only.

The training and testing processes are similar between two approaches: training the model using different classifiers and pick the one which produces the highest testing score. Here we need either a combo: a basic classifier we have seen in lectures such as GaussianNB, SVM, plus a multi-label transforming method such as BinaryRelevance and LabelPowerset, or simply an adapted method, MLkNN, for example. Each of them performs slightly differently between two prediction approaches. Interestingly, the combination of KNeighbors and LabelPowerset wins in both approaches, as though none of their accuracy scores is over 5.0. As expected, I ran into an issue of efficiency when training with the image data since there are still nearly 10 thousand features of each image, after resizing them from 256*192 to 64*48. So, as seen in class, I applied the PCA method to reduce the number of features of each observation to 300. I did not count how much exactly it improves the speed of processing but there must be some.

At last, as the output prediction data is as well in a format of a sparse matrix, I need to do some transformation to turn it back into something verbal. This is a little tricky I think but actually it can be done by applying an ufunc to the matrix. As we have discussed above, the results of predictions are both not that satisfying. I found that other than ‘Clear’, ‘Cloudy’ these kinds of weather that present most frequently, those rarely appearing weather such as ‘Snow’ and ‘Fog’ etc. are nearly never predicted correctly. Checking through the original weather data, I suppose this might be due to that the vast majority of the days are indeed not snowy or foggy, so these kinds of predictions are hardly generated even though the weather data seems to indicate that there is a great probability of a snowy or foggy day. Another guess is that the process of either training or predicting does not take into account the date, especially the month, as one of the important features, since which seasons it does have a huge effect on the tendency of which kind of weather will be present.

Simply putting some data in a simplified ML model is not precise enough to predict the weather. The weather data features did not combine with the images features because it will cause confusion in comparison. If the time is allowed, this combination must be done.

### Project Experience Summary

For the sake of fast debugging and testing, all scripts are written and tested on Jupyter notebook. All calculations and input/output are mainly done with Pandas except initially with Spark since this is one of the most common ways to manipulate small-size data. For I/O, specific techniques are used to read and write the data in format of table or image. For calculation, different kinds of dataframe operations are carried out in order to do aggregation, iteration and data cleaning etc., which can be efficiently accomplished on Pandas.

To make predictions based on provided data, idea of Machine Learning is applied to establish models for classification use. Data is split into training data and testing data such that a ML model is able to set parameters to learn how to predict y from x, and also, users are able to see how the model performs using testing values. When necessary, input data sometimes needs to be transformed to improve processing efficiency while not losing too much reality and accuracy. The best results as the final predictions are not precise enough. The reasons are the high difficulty in weather prediction, the superficial data in comparison, and the simple model on the basis.
